<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Story of NLP: From Rules to Reasoning</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #111827; /* Dark background */
            color: #F9FAFB; /* Light text */
            overflow: hidden;
        }
        .slide {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            padding: 2rem 4rem; /* Adjusted padding */
            opacity: 0;
            transition: opacity 0.6s ease-in-out, transform 0.6s ease-in-out;
            transform: scale(0.95);
            visibility: hidden;
        }
        .slide.active {
            opacity: 1;
            transform: scale(1);
            visibility: visible;
            z-index: 10;
        }
        .slide-content {
            max-width: 1100px; /* Increased max-width */
            width: 100%;
        }
        .progress-bar {
            position: fixed;
            bottom: 0;
            left: 0;
            height: 6px;
            background-color: #3b82f6;
            transition: width 0.3s ease;
            z-index: 50;
        }
        .nav-button {
            position: fixed;
            bottom: 2rem;
            z-index: 20;
            background-color: rgba(31, 41, 55, 0.8);
            color: white;
            border: 1px solid #4B5563;
            border-radius: 9999px;
            padding: 0.75rem;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        .nav-button:hover {
            background-color: #374151;
        }
        #prev-btn {
            left: 2rem;
        }
        #next-btn {
            right: 2rem;
        }
        .slide-counter {
            position: fixed;
            bottom: 2rem;
            left: 50%;
            transform: translateX(-50%);
            z-index: 20;
            background-color: rgba(31, 41, 55, 0.8);
            color: #D1D5DB;
            padding: 0.5rem 1rem;
            border-radius: 9999px;
            font-size: 0.875rem;
        }
        .analogy {
            background-color: #1F2937;
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            border-radius: 0.5rem;
            margin-top: 1.5rem;
        }
        .analogy-title {
            font-weight: 600;
            color: #60a5fa;
            display: flex;
            align-items: center;
        }
        .tech-box {
            background-color: #1F2937;
            border: 1px solid #374151;
            padding: 1.5rem;
            border-radius: 0.75rem;
            margin-top: 1.5rem;
        }
    </style>
</head>
<body>

    <!-- Slide 1: Title -->
    <div id="slide-1" class="slide active text-center">
        <div class="slide-content">
            <h1 class="text-5xl md:text-7xl font-bold tracking-tight text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-indigo-600">The Story of NLP</h1>
            <p class="mt-4 text-2xl md:text-3xl text-gray-300">From Rigid Rules to Fluid Reasoning</p>
            <p class="mt-8 text-lg text-gray-400">A brief journey through the evolution of Natural Language Processing</p>
        </div>
    </div>

    <!-- Slide 2: Rule-Based NLP -->
    <div id="slide-2" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Chapter 1: The Age of Rules (~1950s-1990s)</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">The Recipe Follower</h1>
            <p class="mt-4 text-xl text-gray-300">Early NLP relied on handcrafted rules, grammars, and lexicons.</p>
            <div class="analogy">
                <p class="analogy-title"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2-4 2V4M6 20h12a2 2 0 002-2V6a2 2 0 002-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" /></svg>Storyteller's Analogy</p>
                <p class="mt-2 text-gray-300">Imagine a cook who can only follow a recipe exactly. If a recipe calls for "1 tsp of salt" and you're out, they can't substitute. They don't understand that salt's *function* is to add salinity. Their knowledge is precise, but brittle.</p>
            </div>
        </div>
    </div>

    <!-- Slide 3: Statistical NLP -->
    <div id="slide-3" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Chapter 2: The Statistical Renaissance (~1990s-2010s)</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Learning from Cookbooks</h1>
            <p class="mt-4 text-xl text-gray-300">Instead of rules, models started learning patterns from large text corpora using N-grams, TF-IDF, etc.</p>
            <div class="analogy">
                <p class="analogy-title"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2-4 2V4M6 20h12a2 2 0 002-2V6a2 2 0 002-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" /></svg>Storyteller's Analogy</p>
                <p class="mt-2 text-gray-300">Our cook has now read thousands of recipes. They know that "garlic" and "onion" appear together frequently, but they don't know *why*. They can guess the next likely ingredient in a sequence, but they don't understand the underlying flavor chemistry.</p>
            </div>
        </div>
    </div>
    
    <!-- Slide 4: Word Embeddings -->
    <div id="slide-4" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Chapter 3: The Enlightenment of Meaning (~2013)</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Understanding Flavor Profiles</h1>
             <p class="mt-4 text-xl text-gray-300">Word2Vec and GloVe gave words dense vector representations, capturing semantic relationships.</p>
            <div class="mt-4 p-6 bg-gray-800 rounded-lg text-center">
                <p class="text-xl md:text-2xl font-mono text-gray-300 tracking-wider">
                    <span class="text-blue-300">vector('Lemon')</span> <span class="text-red-400">- vector('Sour')</span> <span class="text-green-400">+ vector('Sweet')</span> <span class="text-gray-400">≈</span> <span class="text-blue-300">vector('Orange')</span>
                </p>
            </div>
            <div class="analogy">
                 <p class="analogy-title"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2-4 2V4M6 20h12a2 2 0 002-2V6a2 2 0 002-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" /></svg>Storyteller's Analogy</p>
                <p class="mt-2 text-gray-300">The cook now understands the *relationships* between ingredients. They have a "flavor map" where similar ingredients like lemon and lime are close. The "direction" from sour to sweet is meaningful. This is a huge leap towards actual cooking.</p>
            </div>
        </div>
    </div>
    
    <!-- Slide 5: RNNs/LSTMs -->
    <div id="slide-5" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Chapter 4: The Age of Sequence (~2014-2017)</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Tasting as You Go</h1>
            <p class="mt-4 text-xl text-gray-300">Recurrent Neural Networks (RNNs) and LSTMs process text sequentially, word by word, remembering past information.</p>
             <div class="analogy">
                 <p class="analogy-title"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2-4 2V4M6 20h12a2 2 0 002-2V6a2 2 0 002-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" /></svg>Storyteller's Analogy</p>
                <p class="mt-2 text-gray-300">Our cook can now taste the soup as they add ingredients one by one. They remember the last few things they added, which informs their next choice. But if the crucial herb was added twenty steps ago, they might have forgotten its subtle flavor by now.</p>
            </div>
        </div>
    </div>

    <!-- Slide 6: The Transformer Revolution -->
    <div id="slide-6" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Chapter 5: The Revolution (2017)</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">"Attention Is All You Need"</h1>
            <p class="mt-4 text-xl text-gray-300">The Transformer architecture abandoned recurrence for a powerful mechanism: <span class="text-blue-300 font-semibold">Self-Attention</span>.</p>
            <p class="mt-4 text-lg text-gray-400">Instead of processing word-by-word, attention allows the model to weigh the importance of all other words in the input for each word it processes, all at once.</p>
             <div class="analogy">
                 <p class="analogy-title"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2-4 2V4M6 20h12a2 2 0 002-2V6a2 2 0 002-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" /></svg>Storyteller's Analogy</p>
                <p class="mt-2 text-gray-300">The cook can now taste every ingredient in the pot simultaneously. They understand how the pinch of paprika is interacting with the beef, how the salt is balancing the tomato, and how the forgotten herb from the beginning is affecting everything. This is a superpower.</p>
            </div>
        </div>
    </div>

    <!-- Slide 7: Overall Architecture -->
    <div id="slide-7" class="slide">
        <div class="slide-content text-center">
            <h1 class="text-4xl md:text-5xl font-bold">The Transformer Architecture</h1>
            <p class="mt-2 text-lg text-gray-400">"Attention is All You Need" - Vaswani et al. 2017</p>
             <div class="mt-4 bg-gray-900 p-4 rounded-lg inline-block shadow-2xl">
                 <img src="image.png" alt="Transformer Architecture Diagram" class="rounded-md mx-auto" style="max-height: 60vh; object-fit: contain;">
            </div>
            <p class="mt-4 text-gray-300">The next slides will explain each component in this diagram.</p>
        </div>
    </div>
    
    <!-- Slide 8: Self-Attention Math -->
    <div id="slide-8" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Deep Dive: The Engine</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">The Math of Self-Attention</h1>
            <p class="text-center font-mono mt-4 text-2xl text-gray-300 bg-gray-900 py-3 rounded-md">Attention(Q, K, V) = softmax( (QKᵀ) / √dₖ ) V</p>
            <div class="mt-4 grid grid-cols-1 md:grid-cols-2 gap-4">
                <div class="bg-gray-800 p-4 rounded-lg">
                    <p class="font-semibold text-lg text-blue-300">1. Create Q, K, V</p>
                    <p class="mt-1 text-gray-300">For each word, create a <b class="text-green-400">Query</b> (what I'm looking for), a <b class="text-yellow-400">Key</b> (what I contain), and a <b class="text-indigo-400">Value</b> (what I actually am) by multiplying its embedding by learned weight matrices.</p>
                </div>
                <div class="bg-gray-800 p-4 rounded-lg">
                    <p class="font-semibold text-lg text-blue-300">2. Score with `QKᵀ`</p>
                    <p class="mt-1 text-gray-300">Calculate the dot product of your word's <b class="text-green-400">Q</b> with every other word's <b class="text-yellow-400">K</b>. This is a raw similarity score.</p>
                </div>
                <div class="bg-gray-800 p-4 rounded-lg">
                    <p class="font-semibold text-lg text-blue-300">3. Scale & Softmax</p>
                    <p class="mt-1 text-gray-300">Divide scores by <b class="text-gray-200">√dₖ</b> for stability, then use softmax to turn scores into attention weights (probabilities that sum to 1).</p>
                </div>
                <div class="bg-gray-800 p-4 rounded-lg">
                    <p class="font-semibold text-lg text-blue-300">4. Get Weighted Sum of `V`</p>
                    <p class="mt-1 text-gray-300">Multiply the weights by each word's <b class="text-indigo-400">Value</b> vector and sum them. This produces a new representation for your word, infused with context.</p>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Slide 9: Positional Encoding -->
    <div id="slide-9" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Deep Dive: The Blueprint</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Piece 1: Positional Encoding</h1>
            <div class="tech-box">
                <h3 class="text-xl font-semibold text-gray-200">The "Why"</h3>
                <p class="mt-1 text-gray-300">Self-Attention is order-agnostic; it sees words as a "bag" without sequence. We need a way to tell the model that "The cat sat on the mat" is different from "The mat sat on the cat."</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">The "How" (The Math)</h3>
                <p class="mt-2 text-gray-300">We create a unique vector for each position in the sequence and add it to the word's embedding. This is done using sine and cosine functions at different frequencies:</p>
                <p class="font-mono text-sm mt-2 text-gray-400">PE(pos, 2i) = sin(pos / 10000^(2i/d))</p>
                <p class="font-mono text-sm text-gray-400">PE(pos, 2i+1) = cos(pos / 10000^(2i/d))</p>
                <p class="mt-2 text-gray-400 text-sm">Where `pos` is the word's position, `i` is the dimension within the vector, and `d` is the total embedding dimension.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">Math Intuition</h3>
                <p class="mt-1 text-gray-300">This formula creates a smooth, unique "fingerprint" for each position. Crucially, it allows the model to easily learn relative positions because the encoding for `pos + k` can be represented as a linear function of the encoding for `pos`.</p>
            </div>
        </div>
    </div>

    <!-- Slide 10: Multi-Head Attention -->
    <div id="slide-10" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Deep Dive: The Specialist Team</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Piece 2: Multi-Head Attention</h1>
             <div class="tech-box">
                <h3 class="text-xl font-semibold text-gray-200">The "Why"</h3>
                <p class="mt-1 text-gray-300">A single attention mechanism might get good at finding one type of relationship (e.g., subject-verb). We want the model to capture many different types of relationships in parallel for a richer understanding.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">The "How" (The Math)</h3>
                <p class="mt-2 text-gray-300">Instead of one set of Q,K,V weight matrices, we create multiple sets (e.g., 8 or 12 "heads"). Each head performs attention independently.</p>
                <p class="font-mono text-sm mt-2 text-gray-400">headᵢ = Attention(QWᵢQ, KWᵢK, VWᵢV)</p>
                <p class="font-mono text-sm mt-2 text-gray-400">MultiHead = Concat(head₁, ..., headₙ)Wᴼ</p>
                 <p class="mt-2 text-gray-400 text-sm">Where `WᵢQ, WᵢK, WᵢV` are the learned matrices for head `i`, and `Wᴼ` is a final output matrix.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">Math Intuition</h3>
                <p class="mt-1 text-gray-300">This is like having a team of specialists. One head might focus on syntactic links, another on semantic similarity, a third on co-reference. We run all their analyses in parallel, then concatenate their findings and combine them with the final `Wᴼ` matrix to produce a holistic representation.</p>
            </div>
        </div>
    </div>

    <!-- Slide 11: FFN -->
    <div id="slide-11" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Deep Dive: The Processor</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Piece 3: Feed-Forward Network</h1>
            <div class="tech-box">
                <h3 class="text-xl font-semibold text-gray-200">The "Why"</h3>
                <p class="mt-1 text-gray-300">The attention layer's job is to gather and mix information from other words. After this, we need a component to actually *process* this new, context-rich information and add more learning capacity.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">The "How" (The Math)</h3>
                <p class="mt-2 text-gray-300">A simple two-layer fully connected neural network is applied independently to each word's vector representation after attention.</p>
                <p class="font-mono text-sm mt-2 text-gray-400">FFN(x) = max(0, xW₁ + b₁)W₂ + b₂</p>
                <p class="mt-2 text-gray-400 text-sm">Where `W₁, b₁` and `W₂, b₂` are learned weights and biases, and `max(0, ...)` is the ReLU activation function.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">Math Intuition</h3>
                <p class="mt-1 text-gray-300">This is the "thinking" part of the block. While attention is about communication between words, the FFN is about computation *within* each word. It provides non-linearity and depth, allowing the model to learn much more complex transformations of the data it has gathered.</p>
            </div>
        </div>
    </div>

    <!-- Slide 12: Residuals and Layer Norm -->
    <div id="slide-12" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Deep Dive: The Stabilizers</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">Piece 4: Residuals & Layer Norm</h1>
            <div class="tech-box">
                <h3 class="text-xl font-semibold text-gray-200">The "Why"</h3>
                <p class="mt-1 text-gray-300">Transformers are very deep, often stacking 48, 96, or more blocks. Training such deep networks is impossible without mechanisms to prevent gradients from vanishing or exploding, ensuring a smooth training process.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">The "How" (The Math)</h3>
                <p class="mt-2 text-gray-300">Each sub-layer (Attention, FFN) is wrapped in these two operations.</p>
                <p class="font-mono text-sm mt-2 text-gray-400">Output = LayerNorm(x + Sublayer(x))</p>
                <p class="mt-2 text-gray-400 text-sm">`Sublayer(x)` is the function implemented by the sub-layer itself (e.g. Multi-Head Attention). `x` is the input to that sub-layer.</p>
                <hr class="my-4 border-gray-700">
                <h3 class="text-xl font-semibold text-gray-200">Math Intuition</h3>
                <p class="mt-1 text-gray-300"><strong class="text-green-400">Residual Connection (`x + ...`):</strong> This creates a "skip-connection" or superhighway. It allows the original input `x` to bypass the sub-layer and be added to its output. This makes it easy for gradients to flow backwards during training and for the model to learn to "ignore" a layer if it's not useful.</p>
                <p class="mt-2 text-gray-300"><strong class="text-yellow-400">Layer Normalization:</strong> This rescales the output vector to have a mean of 0 and a standard deviation of 1. It keeps the numbers in a stable, predictable range as they pass through many layers, which is critical for consistent learning.</p>
            </div>
        </div>
    </div>
    
    <!-- Slide 13: The Transformer Impact -->
    <div id="slide-13" class="slide">
        <div class="slide-content">
            <h1 class="text-4xl md:text-5xl font-bold mt-2">The Transformer Effect</h1>
            <p class="mt-4 text-xl text-gray-300">This new architecture unlocked unprecedented performance and scale.</p>
            <div class="mt-6 grid grid-cols-1 md:grid-cols-2 gap-6 text-center">
                <div class="bg-gray-800 p-6 rounded-lg">
                    <h3 class="text-2xl font-semibold text-blue-400">Parallelization</h3>
                    <p class="mt-2 text-gray-300">Processing all words at once, rather than sequentially, allowed for training on massive datasets and much larger models.</p>
                </div>
                <div class="bg-gray-800 p-6 rounded-lg">
                    <h3 class="text-2xl font-semibold text-green-400">Contextual Understanding</h3>
                    <p class="mt-2 text-gray-300">Self-attention provided a far superior way to handle long-range dependencies and disambiguate word meanings.</p>
                </div>
            </div>
            <p class="mt-8 text-2xl text-center text-gray-300">This led to the "Cambrian Explosion" of models...</p>
        </div>
    </div>

    <!-- Slide 14: BERT, GPT, etc. -->
    <div id="slide-14" class="slide">
        <div class="slide-content">
            <h1 class="text-4xl md:text-5xl font-bold">The Children of the Transformer</h1>
            <p class="mt-4 text-xl text-gray-300">Different philosophies emerged, leading to specialized model families.</p>
            <div class="mt-6 grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="bg-gray-800 p-6 rounded-lg border-l-4 border-blue-500">
                    <h3 class="text-2xl font-bold">BERT: The Encoder</h3>
                    <p class="mt-2 text-gray-400">Bidirectional Encoder Representations from Transformers</p>
                    <p class="mt-3 text-gray-300"><strong>Training Task:</strong> Masked Language Modeling (predicting randomly hidden words) & Next Sentence Prediction.</p>
                    <p class="mt-3 text-gray-300"><strong>Analogy:</strong> The Great Analyst. Reads the entire text at once to build a deep understanding. Perfect for tasks like sentiment analysis, classification, and question answering.</p>
                </div>
                <div class="bg-gray-800 p-6 rounded-lg border-l-4 border-green-500">
                    <h3 class="text-2xl font-bold">GPT: The Decoder</h3>
                    <p class="mt-2 text-gray-400">Generative Pre-trained Transformer</p>
                    <p class="mt-3 text-gray-300"><strong>Training Task:</strong> Causal Language Modeling (predicting the *next* word in a sequence).</p>
                    <p class="mt-3 text-gray-300"><strong>Analogy:</strong> The Creative Author. Reads left-to-right to predict the next word. Perfect for text generation, summarization, and conversation.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 15: The World Today -->
    <div id="slide-15" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">Today: The Age of Giants</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">The Master Chef</h1>
            <p class="mt-4 text-xl text-gray-300">Scaling up Transformers led to unexpected "emergent abilities."</p>
            <ul class="mt-6 list-disc list-inside space-y-2 text-lg text-gray-400">
                <li><strong class="text-purple-300">Scaling Laws:</strong> The discovery that performance predictably improves with more data, larger models (parameters), and more computation.</li>
                <li><strong class="text-blue-300">In-Context Learning:</strong> Models can perform new tasks from just a few examples (few-shot) or even just instructions (zero-shot), without retraining.</li>
                <li><strong class="text-green-300">Chain-of-Thought:</strong> Models can "reason" step-by-step to solve complex problems.</li>
                <li><strong class="text-yellow-300">Multimodality:</strong> Models like Gemini and GPT-4V can understand and process text, images, audio, and video seamlessly.</li>
            </ul>
             <div class="analogy">
                 <p class="analogy-title"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2-4 2V4M6 20h12a2 2 0 002-2V6a2 2 0 002-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" /></svg>Storyteller's Analogy</p>
                <p class="mt-2 text-gray-300">Our cook has become a Master Chef. They don't just follow recipes; they invent them. You can ask for "a dish that feels like a sunny day in Spain," and they can create it, write the recipe, explain the science, and even plate it beautifully (multimodality).</p>
            </div>
        </div>
    </div>

    <!-- Slide 16: The Future -->
    <div id="slide-16" class="slide">
        <div class="slide-content">
            <h2 class="text-sm font-semibold uppercase tracking-widest text-blue-400">The Horizon</h2>
            <h1 class="text-4xl md:text-5xl font-bold mt-2">What's Next? The Frontiers of AI</h1>
            <div class="mt-8 grid grid-cols-1 md:grid-cols-3 gap-6">
                <div class="bg-gray-800 p-4 rounded-lg">
                    <h3 class="text-xl font-semibold text-blue-400">Agents & Tool Use</h3>
                    <p class="mt-2 text-gray-300">LLMs that can browse the web, run code, and interact with APIs to take action in the world.</p>
                </div>
                <div class="bg-gray-800 p-4 rounded-lg">
                    <h3 class="text-xl font-semibold text-green-400">Hyper-Personalization</h3>
                    <p class="mt-2 text-gray-300">Models that adapt to your personal context, data, and style. On-device models will make this fast and private.</p>
                </div>
                <div class="bg-gray-800 p-4 rounded-lg">
                    <h3 class="text-xl font-semibold text-yellow-400">Richer Modalities</h3>
                    <p class="mt-2 text-gray-300">Deeper integration of various data types, moving toward models that experience and understand a more human-like sensory input.</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Slide 17: Conclusion -->
    <div id="slide-17" class="slide text-center">
        <div class="slide-content">
            <h1 class="text-5xl md:text-7xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-indigo-600">Thank You</h1>
            <p class="mt-4 text-2xl md:text-3xl text-gray-300">Q & A</p>
        </div>
    </div>


    <!-- Navigation -->
    <div class="progress-bar" id="progress-bar"></div>
    <div class="slide-counter" id="slide-counter">1 / 17</div>
    <button id="prev-btn" class="nav-button">
        <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7" />
        </svg>
    </button>
    <button id="next-btn" class="nav-button">
        <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" />
        </svg>
    </button>

    <script>
        const slides = document.querySelectorAll('.slide');
        const prevBtn = document.getElementById('prev-btn');
        const nextBtn = document.getElementById('next-btn');
        const progressBar = document.getElementById('progress-bar');
        const slideCounter = document.getElementById('slide-counter');

        let currentSlide = 0;
        const totalSlides = slides.length;

        function updateSlides() {
            slides.forEach((slide, index) => {
                if (index === currentSlide) {
                    slide.classList.add('active');
                } else {
                    slide.classList.remove('active');
                }
            });

            // Update progress bar
            const progress = ((currentSlide + 1) / totalSlides) * 100;
            progressBar.style.width = `${progress}%`;

            // Update slide counter
            slideCounter.textContent = `${currentSlide + 1} / ${totalSlides}`;
            
            // Hide/show nav buttons
            prevBtn.style.display = currentSlide === 0 ? 'none' : 'block';
            nextBtn.style.display = currentSlide === totalSlides - 1 ? 'none' : 'block';
        }

        function nextSlide() {
            if (currentSlide < totalSlides - 1) {
                currentSlide++;
                updateSlides();
            }
        }

        function prevSlide() {
            if (currentSlide > 0) {
                currentSlide--;
                updateSlides();
            }
        }

        // Event Listeners
        nextBtn.addEventListener('click', nextSlide);
        prevBtn.addEventListener('click', prevSlide);

        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowRight' || e.key === ' ') {
                nextSlide();
            } else if (e.key === 'ArrowLeft') {
                prevSlide();
            }
        });

        // Initial setup
        updateSlides();
    </script>

</body>
</html>

