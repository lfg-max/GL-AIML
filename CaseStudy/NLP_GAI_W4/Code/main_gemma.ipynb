{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png\" width=\"300\" height=\"100\"/>\n",
    "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/></center>\n",
    "\n",
    "<center><font size=10>Artificial Intelligence and Machine Learning</center></font>\n",
    "<center><font size=6>Natural Language Processing with Generative AI - Retrieval Augmented Generation</center></font>\n",
    "\n",
    "<center><img src=\"https://i.ibb.co/pBF9nKpf/apple.png\" width=\"720\"></center>\n",
    "\n",
    "<center><font size=6>Apple HBR Report Document Q&A</center></font>\n",
    "\n",
    "# RAG LLM Application Notebook\n",
    "\n",
    "This notebook demonstrates the complete workflow of a Retrieval-Augmented Generation (RAG) LLM application. It covers data loading, chunking, embedding, vector database setup, question answering, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Installation\n",
    "\n",
    "First, we need to install all the necessary Python libraries. This ensures that all dependencies for data processing, LLM interaction, and vector database operations are met. If you are running this in a Colab environment, these commands will typically install the packages.\n",
    "\n",
    "**Note**: If you are running this locally, ensure you have Ollama installed and the `llama3.2` model pulled (`ollama pull llama3.2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All specified packages installed (or upgraded) successfully!\n",
      "Please ensure the model is pulled for Ollama with the command:\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "# %pip install -U -q huggingface_hub tiktoken pymupdf langchain-community langchain langchain-chroma langchain-huggingface ollama\n",
    "\n",
    "\n",
    "print(\"All specified packages installed (or upgraded) successfully!\")\n",
    "print(\"Please ensure the model is pulled for Ollama with the command:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Necessary Modules\n",
    "\n",
    "We import the `RAG_LLM` class from `functions.py` and constants from `config.py`. Make sure `functions.py`, `config.py`, and `prompt_templates.py` are in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from functions import RAG_LLM\n",
    "from config import APPLE_PDF_PATH, DEFAULT_K_RETRIEVER, DEFAULT_MAX_TOKENS, DEFAULT_TEMPERATURE\n",
    "import os\n",
    "\n",
    "print(\"Modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize the RAG_LLM System\n",
    "\n",
    "Here, we create an instance of our `RAG_LLM` class. This object will manage the entire RAG pipeline, including data loading, processing, retrieval, and LLM interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG_LLM initialized.\n",
      "RAG_LLM system initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG_LLM class\n",
    "rag_system = RAG_LLM()\n",
    "print(\"RAG_LLM system initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the PDF Document\n",
    "\n",
    "We load the `HBR_How_Apple_Is_Organized_For_Innovation.pdf` document. Ensure this PDF file is available in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: HBR_How_Apple_Is_Organized_For_Innovation.pdf\n",
      "Successfully loaded 11 pages.\n",
      "PDF document loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF document\n",
    "documents = rag_system.load_data(pdf_path=APPLE_PDF_PATH)\n",
    "if not documents:\n",
    "    print(\"Failed to load documents. Please check the PDF path and file existence.\")\n",
    "else:\n",
    "    print(\"PDF document loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chunk the Loaded Data\n",
    "\n",
    "The loaded document is chunked into smaller, overlapping segments. This is crucial for efficient retrieval and to fit content within the LLM's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking data with chunk_size=1024, chunk_overlap=20\n",
      "Created 16 chunks.\n",
      "Documents chunked successfully.\n"
     ]
    }
   ],
   "source": [
    "# Chunk the loaded data\n",
    "document_chunks = rag_system.chunk_data(documents)\n",
    "if not document_chunks:\n",
    "    print(\"Failed to chunk documents.\")\n",
    "else:\n",
    "    print(\"Documents chunked successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Embedding Model\n",
    "\n",
    "An embedding model (SentenceTransformer) is initialized to convert text chunks into numerical vectors, enabling semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing embedding model: mixedbread-ai/mxbai-embed-large-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model initialized successfully.\n",
      "Embedding model created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create embedding model\n",
    "rag_system.create_embeddings()\n",
    "if not rag_system.embedding_model:\n",
    "    print(\"Failed to create embedding model.\")\n",
    "else:\n",
    "    print(\"Embedding model created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Set Up the Vector Database\n",
    "\n",
    "The Chroma vector database is set up using the chunked documents and the embedding model. This database will store the embeddings and facilitate quick retrieval of relevant context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up vector database in: vector_db_1024\n",
      "Vector database loaded from existing directory.\n",
      "Retriever initialized.\n",
      "Vector database set up and retriever initialized.\n"
     ]
    }
   ],
   "source": [
    "# Set up the vector database\n",
    "rag_system.setup_vector_database(document_chunks=document_chunks)\n",
    "if not rag_system.vectorstore:\n",
    "    print(\"Failed to set up vector database.\")\n",
    "else:\n",
    "    print(\"Vector database set up and retriever initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demonstrate Question Answering with RAG\n",
    "\n",
    "Now, we can ask questions and see how the RAG system retrieves relevant information and generates answers based on the loaded document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: Who are the authors of this article and who published this article ?\n",
      "Retrieving 3 relevant documents for the query.\n",
      "RAG prompt created.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Response 1: \n",
      "Joel M. Podolny, Morten T. Hansen, and Harvard Business Review.\n"
     ]
    }
   ],
   "source": [
    "# Example Query 1\n",
    "user_input_1 = \"Who are the authors of this article and who published this article ?\"\n",
    "print(f\"\\nQuery 1: {user_input_1}\")\n",
    "llm_response_1 = rag_system.get_answer(user_input_1)\n",
    "print(f\"Response 1: \\n{llm_response_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 2: List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\n",
      "Retrieving 3 relevant documents for the query.\n",
      "RAG prompt created.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Response 2: \n",
      "Here are the three leadership characteristics from the text, explained in two lines or less:\n",
      "\n",
      "*   **Deep Expertise:** Leaders are expected to possess a significant level of knowledge and skill within their specific function. This allows them to guide and mentor others effectively.\n",
      "\n",
      "*   **Immersion in Details:** Leaders need to be deeply involved in the specifics of their work, understanding the nuances and complexities of their area.\n",
      "\n",
      "*   **Collaborative Debate:** Leaders are expected to engage in open discussion and exchange ideas with others, fostering a culture of shared learning and innovation.\n"
     ]
    }
   ],
   "source": [
    "# Example Query 2\n",
    "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
    "print(f\"\\nQuery 2: {user_input_2}\")\n",
    "# Adjust max_tokens to allow for a more complete answer for a list\n",
    "llm_response_2 = rag_system.get_answer(user_input_2, max_tokens=150, temperature=0.1)\n",
    "print(f\"Response 2: \\n{llm_response_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 3: Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\n",
      "Retrieving 3 relevant documents for the query.\n",
      "RAG prompt created.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Response 3: \n",
      "According to the article, Apple’s approach to leadership has led to successful innovations through several specific examples:\n",
      "\n",
      "*   **Roger Rosner’s Role as VP of Applications:** Rosner’s experience demonstrates how Apple’s leaders are expected to exercise discretion. He manages a portfolio of applications (News, Clips, Books, Final Cut Pro) where he doesn’t need to be an expert in all areas. Instead, he focuses on the areas where his expertise is most valuable, and delegates or learns about other areas as needed.\n",
      "\n",
      "*   **The Overall Leadership Model:** The article highlights that Apple’s leaders are expected to “lead experts,” meaning they focus on the areas where they have deep expertise while delegating or learning about other areas. This approach has been instrumental in driving innovation across the company, not just in product development.\n"
     ]
    }
   ],
   "source": [
    "# Example Query 3 (expected to be \"I don't know\" if not in context)\n",
    "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
    "print(f\"\\nQuery 3: {user_input_3}\")\n",
    "llm_response_3 = rag_system.get_answer(user_input_3)\n",
    "print(f\"Response 3: \\n{llm_response_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Demonstrate Output Evaluation (LLM-as-a-Judge)\n",
    "\n",
    "Finally, we demonstrate how the RAG system can evaluate its own answers for 'groundedness' (adherence to context) and 'relevance' (how well it answers the question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Query 1:\n",
      "\n",
      "--- Calculating Ratings for Question: 'Who are the authors of this article and who published this article ?' ---\n",
      "Retrieving 3 relevant documents for the query.\n",
      "RAG prompt created.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Rating overall answer quality (groundedness and relevance)...\n",
      "Rating groundedness...\n",
      "Retrieving 3 relevant documents for the query.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Rating relevance...\n",
      "Retrieving 3 relevant documents for the query.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "\n",
      "--- Results ---\n",
      "Question: \n",
      " Who are the authors of this article and who published this article ?\n",
      "\n",
      "Answer: \n",
      " Joel M. Podolny, Morten T. Hansen, and Harvard Business Review.\n",
      "\n",
      "Groundedness Rating: \n",
      " Okay, let's evaluate the answer based on the provided metric.\n",
      "\n",
      "**Steps for Evaluation:**\n",
      "\n",
      "1.  **Identify Information in Context:** Carefully read the context to identify all names mentioned as authors or publishers of the article.\n",
      "2.  **Compare to Question:** Determine if the answer accurately lists all the individuals mentioned in the context who are associated with the article.\n",
      "3.  **Assess Adherence to Metric:**  Determine if the answer is solely derived from the information presented in the context.  It should not include external knowledge.\n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1.  **Information in Context:** The context lists the following individuals:\n",
      "    *   Joel M. Podolny\n",
      "    *   Morten T. Hansen\n",
      "    *   Harvard Business Review\n",
      "\n",
      "2.  **Compare to Question:** The answer provided is “Joel M. Podolny, Morten T. Hansen, and Harvard Business Review.” This accurately lists all the authors and publisher mentioned in the context.\n",
      "\n",
      "3.  **Assess Adherence to Metric:** The answer is entirely derived from the information presented in the context. It does not include any external knowledge or assumptions.\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "*   **Score:** 5 - The metric is followed completely.\n",
      "\n",
      "**Reasoning:**\n",
      "\n",
      "The answer perfectly fulfills the requirement of extracting information solely from the provided context. It correctly identifies all the authors and publisher as stated in the text. There is no extraneous information.\n",
      "\n",
      "Relevance Rating: \n",
      " Okay, let's evaluate the context against the provided metric (relevance).\n",
      "\n",
      "**Steps to Evaluate:**\n",
      "\n",
      "1.  **Identify the Question's Core Requirements:** The question asks for *both* the authors of the article *and* the publisher.\n",
      "2.  **Scan the Context for Author Names:**  Carefully read through the text, looking for names associated with authorship.\n",
      "3.  **Identify the Publisher:** Locate the name of the organization responsible for publishing the article.\n",
      "4.  **Verify Completeness:** Ensure that *all* aspects of the question are addressed within the context.\n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1.  The context immediately states: \"Joel M. Podolny, Morten T. Hansen, and Harvard Business Review.\" This directly answers the first part of the question.\n",
      "2.  The text explicitly identifies \"Harvard Business Review\" as the publisher.\n",
      "3.  There is no other author information present in the context.\n",
      "\n",
      "**Assessment of Relevance:**\n",
      "\n",
      "The context *completely* addresses all aspects of the question. It provides the names of the authors (Joel M. Podolny, Morten T. Hansen, and Harvard Business Review) and identifies Harvard Business Review as the publisher.\n",
      "\n",
      "**Rating:**\n",
      "\n",
      "5 - The metric is followed completely.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Query 1\n",
    "user_input_1 = \"Who are the authors of this article and who published this article ?\"\n",
    "print(\"\\nEvaluating Query 1:\")\n",
    "rag_system.calculate_rating(question=user_input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Query 2:\n",
      "\n",
      "--- Calculating Ratings for Question: 'List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.' ---\n",
      "Retrieving 3 relevant documents for the query.\n",
      "RAG prompt created.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Rating overall answer quality (groundedness and relevance)...\n",
      "Rating groundedness...\n",
      "Retrieving 3 relevant documents for the query.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Rating relevance...\n",
      "Retrieving 3 relevant documents for the query.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "\n",
      "--- Results ---\n",
      "Question: \n",
      " List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\n",
      "\n",
      "Answer: \n",
      " Here are the three leadership characteristics from the text, explained in two lines or less:\n",
      "\n",
      "*   **Deep Expertise:** Leaders are expected to possess a significant level of knowledge and skill within their specific function. This allows them to guide and mentor others effectively.\n",
      "\n",
      "*   **Immersion in Details:** Leaders need to be deeply involved in the specifics of their work, understanding the nuances and complexities of their area.\n",
      "\n",
      "*   **Collaborative Debate:** Leaders are expected to engage in open discussion and debate with others, fostering a culture of shared learning and decision-making.\n",
      "\n",
      "Groundedness Rating: \n",
      " **Evaluation:**\n",
      "\n",
      "**Step 1: Understanding the Metric**\n",
      "\n",
      "The metric requires extracting leadership characteristics directly from the provided context, presented in bullet points and explained concisely (two lines or less per point). The response must avoid adding information not present in the text.\n",
      "\n",
      "**Step 2: Step-by-Step Analysis of the Answer**\n",
      "\n",
      "The answer accurately identifies the three leadership characteristics mentioned in the text: deep expertise, immersion in details, and collaborative debate. Each characteristic is presented in the requested format – a bullet point followed by a two-line explanation. The explanations are derived solely from the context.\n",
      "\n",
      "**Step 3: Evaluation of Adherence to the Metric**\n",
      "\n",
      "The answer adheres to the metric completely. It extracts the information directly from the provided text and presents it in the specified format. There is no extraneous information or interpretation.\n",
      "\n",
      "**Step 4: Rating the Answer**\n",
      "\n",
      "Based on the above analysis, the answer receives a score of **5**. It fully meets all the criteria of the metric.\n",
      "\n",
      "Relevance Rating: \n",
      " **Evaluation:**\n",
      "\n",
      "1.  **Step 1: Analyze the Context for Relevance:**\n",
      "    *   The context describes Apple’s leadership model, particularly as it evolved due to the company’s growth and new ventures (iPhone, new apps, etc.). It highlights three key characteristics: deep expertise, immersion in details, and collaborative debate. The goal is to identify these characteristics and explain them concisely.\n",
      "\n",
      "2.  **Step 2: Step-by-Step Explanation of Relevance:**\n",
      "    *   The text explicitly states the three leadership characteristics. It then provides a brief explanation of each, drawing directly from the context. The explanations are tied to the examples of Roger Rosner and Apple’s organizational structure. The context provides the foundation for these characteristics.\n",
      "\n",
      "3.  **Step 3: Evaluate the Extent of Metric Following:**\n",
      "    *   The answer successfully identifies the three leadership characteristics presented in the context: deep expertise, immersion in details, and collaborative debate. Each characteristic is explained in two lines or less, as requested. The explanations are directly derived from the provided text.\n",
      "\n",
      "4.  **Rating:** 5 - The metric is followed completely. The answer accurately extracts and explains the three leadership characteristics from the context, adhering to all the given requirements.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Query 2\n",
    "user_input_2 = \"List down the three leadership characteristics in bulleted points and explain each one of the characteristics under two lines.\"\n",
    "print(\"\\nEvaluating Query 2:\")\n",
    "# Using parameters that yield a better answer for evaluation\n",
    "rag_system.calculate_rating(question=user_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Query 3:\n",
      "\n",
      "--- Calculating Ratings for Question: 'Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?' ---\n",
      "Retrieving 3 relevant documents for the query.\n",
      "RAG prompt created.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Rating overall answer quality (groundedness and relevance)...\n",
      "Rating groundedness...\n",
      "Retrieving 3 relevant documents for the query.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "Rating relevance...\n",
      "Retrieving 3 relevant documents for the query.\n",
      "Generating LLM response using model: gemma3:4b\n",
      "LLM response generated.\n",
      "\n",
      "--- Results ---\n",
      "Question: \n",
      " Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\n",
      "\n",
      "Answer: \n",
      " According to the article, Apple’s approach to leadership has led to successful innovations through several specific examples:\n",
      "\n",
      "*   **Roger Rosner’s Role as VP of Applications:** Rosner’s experience demonstrates how Apple’s leaders are expected to exercise discretion. He manages a portfolio of applications (News, Clips, Books, Final Cut Pro) where he doesn’t need to be an expert in all areas. Instead, he focuses on the areas where his expertise is most valuable, and delegates or learns about other areas as needed.\n",
      "\n",
      "*   **The Overall Leadership Model:** The article highlights that Apple’s leaders are expected to “lead experts,” meaning they focus on the areas where they have deep expertise while delegating or learning about other areas. This approach has been instrumental in driving innovation across the company, not just in product development.\n",
      "\n",
      "Groundedness Rating: \n",
      " **Evaluation:**\n",
      "\n",
      "1.  **Steps for Evaluation:**\n",
      "    *   Identify the specific examples of Apple’s leadership approach that led to innovation, as described in the context.\n",
      "    *   Analyze how each example demonstrates the leadership model.\n",
      "    *   Assess the extent to which the answer accurately reflects the information provided in the context.\n",
      "\n",
      "2.  **Step-by-Step Explanation:**\n",
      "    *   The answer correctly identifies Roger Rosner’s role as a key example. It accurately describes his situation – managing a diverse portfolio of applications where he doesn’t need to be an expert in all areas.\n",
      "    *   The answer correctly explains that the core of Apple’s leadership model is “leading experts,” emphasizing the focus on areas of deep expertise and delegation/learning in other areas.\n",
      "    *   The answer successfully connects these examples to the overall innovation success of Apple.\n",
      "\n",
      "3.  **Assessment of Metric Adherence:**\n",
      "    *   The answer is entirely derived from the information presented in the context. It doesn’t introduce any external information or interpretations. It directly quotes and summarizes the key points about Apple’s leadership model.\n",
      "\n",
      "4.  **Rating:**\n",
      "\n",
      "    *   **Score: 5** - The metric is followed completely. The answer accurately and comprehensively summarizes the specific examples and the core principles of Apple’s leadership approach as presented in the context. It demonstrates a thorough understanding of the provided information.\n",
      "\n",
      "Relevance Rating: \n",
      " **Evaluation:**\n",
      "\n",
      "1.  **Step 1: Analyze the Question:** The question asks for specific examples from the article where Apple’s leadership approach led to successful innovations. It requires identifying instances where Apple’s leadership model contributed to innovation.\n",
      "\n",
      "2.  **Step 2: Step-by-Step Breakdown of the Context:**\n",
      "    *   The context primarily describes Apple’s shift from a decentralized, business unit structure to a functional organization under Steve Jobs and maintained by Tim Cook.\n",
      "    *   It details the challenges of managing a rapidly growing company and how Apple’s leaders address these challenges through a “discretionary leadership model.”\n",
      "    *   The core of the example is provided through Roger Rosner’s role as VP of Applications, illustrating the model in action.\n",
      "\n",
      "3.  **Step 3: Assessment of Relevance:** The answer successfully identifies a specific example (Rosner’s role) and explains how it exemplifies Apple’s leadership approach. It accurately describes the key elements of the model – focusing on core expertise and delegating or learning in other areas.\n",
      "\n",
      "4.  **Rating:** 5 - The metric is followed completely. The answer directly addresses the question by providing a concrete example from the text and clearly explaining how that example demonstrates Apple’s leadership approach to innovation. It captures all the important aspects of the question and the relevant information from the context.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Query 3\n",
    "user_input_3 = \"Can you explain specific examples from the article where Apple's approach to leadership has led to successful innovations?\"\n",
    "print(\"\\nEvaluating Query 3:\")\n",
    "rag_system.calculate_rating(question=user_input_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a comprehensive walkthrough of setting up and using a RAG LLM system for document Q&A and evaluation. You can modify the parameters and queries to experiment further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e1869",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
